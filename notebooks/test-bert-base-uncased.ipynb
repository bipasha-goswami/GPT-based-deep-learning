{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 175kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [00:13<00:00, 32.7MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 5.48kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.59MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 6.03MB/s]\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked Language Modelling Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0670582503080368,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i'm a fashion model\"},\n",
       " {'score': 0.0589725524187088,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello, i'm a new model\"},\n",
       " {'score': 0.054145969450473785,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello, i'm a super model\"},\n",
       " {'score': 0.041718654334545135,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello, i'm a role model\"},\n",
       " {'score': 0.03996806591749191,\n",
       "  'token': 2944,\n",
       "  'token_str': 'model',\n",
       "  'sequence': \"hello, i'm a model model\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masked langauge modelling\n",
    "unmasker(\"Hello, I'm a [MASK] model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# getting the features of a given text (text representations)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "text = \"Hello, I'm a super model\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0518, -0.0754,  0.1140,  ..., -0.2333,  0.4524,  0.4513],\n",
       "         [ 0.2589,  0.1179,  0.0226,  ..., -0.2185,  1.0233, -0.0636],\n",
       "         [-0.2194,  0.4313,  0.5258,  ..., -0.7316,  0.6713,  0.2673],\n",
       "         ...,\n",
       "         [ 0.2997, -0.3274,  0.9692,  ..., -0.8895,  0.3568, -0.0777],\n",
       "         [ 0.2039, -0.4854, -0.0722,  ..., -0.1137,  0.3147, -0.5153],\n",
       "         [ 0.2543,  0.3109,  0.3004,  ...,  0.2110, -0.4983, -0.1760]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-5.8465e-01, -3.0469e-01, -5.9026e-03,  1.9225e-01,  2.6193e-01,\n",
       "         -1.2453e-01,  2.9534e-01,  1.7861e-01,  2.5144e-01, -9.9848e-01,\n",
       "          3.2515e-01,  2.9257e-01,  9.7584e-01, -4.9368e-02,  8.0692e-01,\n",
       "         -3.8713e-01,  6.2257e-02, -4.3808e-01,  1.9329e-01,  4.6033e-01,\n",
       "          4.1241e-01,  9.9187e-01,  5.2173e-01,  2.4685e-01,  1.9937e-01,\n",
       "          2.8932e-01, -5.1003e-01,  8.5106e-01,  9.1631e-01,  6.2540e-01,\n",
       "         -1.1849e-01, -1.3609e-02, -9.8765e-01, -6.7243e-02, -3.7505e-01,\n",
       "         -9.7458e-01,  1.0096e-01, -6.1104e-01,  1.3072e-01,  3.0557e-01,\n",
       "         -8.1694e-01,  1.4818e-01,  9.9734e-01, -6.5764e-01,  2.7692e-02,\n",
       "         -1.7045e-01, -9.9701e-01,  1.2826e-01, -7.9387e-01, -2.9786e-01,\n",
       "          6.7348e-02, -7.9375e-02, -9.3157e-02,  1.3514e-01,  3.3065e-01,\n",
       "          1.8226e-01, -2.9727e-01,  1.9729e-03, -1.7929e-01, -4.0337e-01,\n",
       "         -6.1196e-01,  2.7111e-01, -2.9409e-01, -7.4867e-01, -4.1129e-03,\n",
       "          8.7298e-02, -2.6088e-02, -9.8700e-02,  7.7107e-02, -1.3513e-01,\n",
       "          5.6082e-01,  9.8428e-02,  4.9113e-01, -7.9676e-01, -4.6027e-01,\n",
       "          1.3384e-01, -5.7056e-01,  9.9997e-01,  5.8252e-02, -9.7299e-01,\n",
       "          2.4021e-01, -1.2186e-01,  4.0790e-01,  4.7419e-01, -2.8796e-01,\n",
       "         -9.9979e-01,  9.5921e-02, -3.3201e-02, -9.8729e-01,  6.5189e-02,\n",
       "          3.9181e-01, -1.1771e-01,  1.0047e-01,  4.8491e-01, -1.9634e-01,\n",
       "         -8.0682e-02,  4.7082e-03, -1.8166e-01, -8.5700e-02, -5.5012e-02,\n",
       "          9.3357e-03,  1.7880e-02, -1.2400e-01, -2.4046e-01,  9.9951e-02,\n",
       "         -2.6256e-01,  5.0433e-02,  1.4972e-01, -2.8588e-01,  3.9654e-01,\n",
       "          4.0164e-01, -2.5619e-01,  1.6606e-01, -9.1815e-01,  3.0767e-01,\n",
       "         -2.0091e-01, -9.7397e-01, -4.2411e-01, -9.8559e-01,  5.2092e-01,\n",
       "          4.7079e-02, -1.8663e-01,  8.6887e-01,  5.2311e-01,  2.3060e-01,\n",
       "          1.2851e-01,  2.6603e-01, -9.9999e-01, -9.7831e-02, -2.5625e-01,\n",
       "          1.8602e-01,  1.0707e-03, -9.6244e-01, -9.5619e-01,  4.3028e-01,\n",
       "          8.9499e-01, -1.5735e-02,  9.9407e-01,  4.3416e-02,  9.1309e-01,\n",
       "          3.7843e-01, -2.8494e-01, -1.6614e-01, -2.6909e-01,  3.9552e-01,\n",
       "         -4.2628e-01, -8.4895e-02,  1.9781e-01, -2.3180e-02, -3.9326e-01,\n",
       "         -1.3244e-02,  4.5781e-03,  1.0677e-01, -8.7274e-01, -2.5187e-01,\n",
       "          9.0413e-01, -8.9718e-02, -3.6517e-02,  4.5198e-01, -1.0130e-01,\n",
       "         -1.5309e-01,  6.8277e-01,  3.8785e-01,  2.0269e-01, -8.9244e-02,\n",
       "          2.2594e-01, -4.9490e-01,  2.1056e-01, -6.2534e-01,  5.6763e-01,\n",
       "          2.5376e-01, -1.3722e-01, -2.4052e-01, -9.7003e-01, -9.3110e-02,\n",
       "          1.2754e-01,  9.8242e-01,  4.2240e-01,  5.2078e-02, -2.9887e-01,\n",
       "         -1.9851e-01,  4.2051e-02, -9.3859e-01,  9.7174e-01,  1.6028e-02,\n",
       "          2.5876e-01, -1.3413e-01,  2.2011e-02, -7.0618e-01, -1.9608e-01,\n",
       "          2.7501e-01,  1.3120e-01, -6.4668e-01,  4.6236e-02, -4.7066e-01,\n",
       "         -1.0666e-01, -3.0589e-01, -2.1800e-02, -1.6603e-01, -2.9454e-01,\n",
       "          4.3806e-02,  8.8228e-01,  6.3451e-01,  2.7779e-01, -4.4724e-01,\n",
       "          3.0619e-01, -7.6233e-01, -1.2793e-01, -1.4377e-01,  8.4341e-02,\n",
       "          1.0142e-01,  9.7924e-01, -3.5194e-01,  3.7663e-02, -8.6107e-01,\n",
       "         -9.7923e-01, -2.0655e-01, -7.3887e-01, -9.8380e-02, -3.9527e-01,\n",
       "          2.6549e-01,  8.0458e-02, -4.6778e-01,  1.2126e-01, -5.4956e-01,\n",
       "         -5.1017e-01,  1.5224e-01, -2.2338e-01,  3.2575e-01, -2.1800e-01,\n",
       "          8.7469e-01,  4.3049e-01, -3.5510e-01, -3.1361e-02,  9.2678e-01,\n",
       "         -5.2947e-01, -7.1196e-01,  2.0805e-01, -9.2215e-02,  5.6380e-01,\n",
       "         -3.5041e-01,  9.1302e-01,  3.6246e-01,  2.0877e-01, -8.1998e-01,\n",
       "         -1.9952e-02, -4.9801e-01,  3.0977e-01,  5.8523e-02, -5.8701e-01,\n",
       "         -3.4241e-02,  4.9253e-01,  2.0215e-01,  7.0749e-01, -8.9280e-02,\n",
       "          5.9178e-01, -9.5271e-01, -9.4818e-01, -6.9337e-01,  4.1281e-01,\n",
       "         -9.8458e-01, -2.6386e-02,  2.8837e-01, -4.0086e-02, -1.3434e-01,\n",
       "         -1.2709e-01, -9.4742e-01,  2.1834e-01, -7.4094e-02,  7.6041e-01,\n",
       "         -1.1250e-01, -3.9141e-01, -8.6784e-02, -9.1823e-01, -2.1010e-01,\n",
       "         -4.1649e-02,  4.6024e-01, -2.5103e-01, -8.8657e-01,  3.6349e-01,\n",
       "          4.6073e-01,  2.9992e-01,  1.8636e-01,  9.0032e-01,  9.9958e-01,\n",
       "          9.5581e-01,  8.3149e-01,  3.3150e-01, -9.6232e-01, -6.7947e-01,\n",
       "          9.9945e-01, -6.6939e-01, -9.9983e-01, -8.6038e-01, -2.7253e-01,\n",
       "          1.5217e-01, -9.9999e-01, -1.2299e-01,  2.2637e-01, -8.4067e-01,\n",
       "         -3.2117e-01,  9.4799e-01,  6.7456e-01, -9.9997e-01,  5.2501e-01,\n",
       "          7.8002e-01, -5.6880e-01,  3.5270e-01, -1.8047e-01,  9.5339e-01,\n",
       "          2.7406e-01,  3.2201e-01,  5.3693e-04,  3.4936e-01, -5.7579e-01,\n",
       "         -4.6182e-01,  3.9756e-01, -3.3227e-01,  8.8901e-01,  3.4050e-02,\n",
       "         -3.1180e-01, -7.7298e-01,  9.9607e-02,  2.6588e-02, -4.6104e-01,\n",
       "         -9.4410e-01, -1.7928e-01, -5.0809e-01,  5.1478e-01, -7.5624e-02,\n",
       "          1.6055e-01, -3.1820e-01,  9.7263e-02, -3.7645e-01, -2.8543e-01,\n",
       "          5.6725e-01, -8.4606e-01,  5.0113e-02,  5.4064e-02, -6.4661e-01,\n",
       "          1.6611e-01, -9.6111e-01,  9.1509e-01, -1.7512e-01, -2.9643e-01,\n",
       "          9.9998e-01, -3.8504e-01, -5.7736e-01,  4.6927e-01,  8.3674e-02,\n",
       "         -1.1613e-01,  9.9987e-01,  5.4686e-01, -9.6960e-01, -4.4703e-01,\n",
       "          3.3822e-01, -3.1773e-01, -2.9749e-01,  9.9282e-01, -1.0155e-01,\n",
       "          2.4041e-01,  3.8733e-01,  9.8415e-01, -9.8149e-01,  8.8069e-01,\n",
       "         -6.4214e-01, -9.5084e-01,  9.3854e-01,  9.0682e-01, -1.9127e-01,\n",
       "         -3.6219e-01, -1.4151e-01,  1.6068e-01, -4.0096e-03, -7.4746e-01,\n",
       "          1.6029e-01,  1.3654e-01, -7.8419e-03,  8.0558e-01,  4.4554e-02,\n",
       "         -5.5169e-01,  8.4495e-02, -1.8523e-01,  5.8049e-01,  2.2876e-01,\n",
       "          1.4634e-01, -8.5311e-02, -3.3807e-02, -2.0201e-01, -5.4849e-01,\n",
       "         -9.4882e-01,  2.6916e-01,  9.9996e-01,  2.2406e-01, -1.0214e-02,\n",
       "          1.7220e-01,  2.0404e-02, -3.5115e-01,  2.3087e-01,  3.6842e-01,\n",
       "         -9.5794e-02, -5.1063e-01, -8.0728e-02, -5.1636e-01, -9.8840e-01,\n",
       "          1.8024e-01,  7.5282e-02, -3.3365e-02,  9.8008e-01, -3.6187e-02,\n",
       "          9.4652e-02, -8.4813e-02,  1.7030e-01, -8.8040e-02,  1.7215e-01,\n",
       "         -8.6705e-02,  9.6743e-01, -2.1555e-01,  5.0405e-01,  2.0670e-01,\n",
       "          8.4239e-02, -3.0404e-01, -4.6430e-01, -3.6734e-02, -9.1720e-01,\n",
       "          1.6076e-01, -9.2310e-01,  9.4076e-01,  1.3834e-01,  1.5656e-01,\n",
       "          8.6657e-02,  1.3256e-01,  9.9998e-01, -6.1520e-01,  3.2716e-01,\n",
       "          6.3822e-01,  7.7171e-02, -9.7305e-01, -3.3334e-01, -2.6961e-01,\n",
       "          9.3386e-02,  2.2517e-01, -1.0998e-01,  8.0707e-02, -9.2961e-01,\n",
       "         -2.0924e-01, -2.5408e-01, -7.4864e-01, -9.6809e-01,  3.8503e-01,\n",
       "          1.6369e-01, -4.0800e-02, -7.1766e-01, -4.1519e-01, -4.8068e-01,\n",
       "         -2.6920e-01,  3.8594e-02, -8.9612e-01,  5.5963e-01, -1.0097e-01,\n",
       "          1.7275e-01, -7.3331e-02,  5.1676e-01,  2.2602e-02,  8.8694e-01,\n",
       "         -1.7469e-02,  1.2360e-01, -2.4593e-02, -5.4447e-01,  4.9341e-01,\n",
       "         -4.0338e-01, -4.8223e-02, -9.9778e-02,  9.9998e-01, -2.3029e-01,\n",
       "          3.4913e-01,  2.5352e-01,  2.8283e-01,  5.6921e-03,  2.0068e-01,\n",
       "          4.3409e-01,  1.6262e-01,  4.9512e-02,  2.1445e-01,  6.4471e-01,\n",
       "         -8.5709e-03,  2.0872e-01, -4.7239e-02, -1.6440e-01,  6.9423e-01,\n",
       "          4.9345e-01,  9.6564e-02,  1.0583e-01, -1.4211e-01,  8.3006e-01,\n",
       "          1.7026e-01,  1.9361e-01, -1.2170e-01,  1.0772e-01, -2.3766e-01,\n",
       "          3.3471e-01,  9.9995e-01,  1.2648e-01, -3.1623e-01, -9.8646e-01,\n",
       "         -1.1825e-01, -5.2457e-01,  9.9893e-01,  8.3366e-01, -3.7917e-01,\n",
       "          3.4320e-01,  1.7018e-01, -1.2733e-01,  2.0802e-01, -6.9748e-02,\n",
       "         -1.3895e-01,  7.5935e-02,  1.3688e-02,  9.3775e-01, -4.3002e-01,\n",
       "         -9.6221e-01, -4.9982e-01,  6.6704e-02, -9.3488e-01,  9.8265e-01,\n",
       "         -2.9509e-01, -8.6920e-02, -2.3303e-01,  3.6328e-01, -7.6113e-01,\n",
       "         -1.5569e-01, -9.6984e-01,  7.9113e-02,  9.9313e-02,  9.2557e-01,\n",
       "          1.1273e-01, -5.2263e-01, -6.9976e-01, -2.6829e-01,  1.0735e-01,\n",
       "          7.5550e-02, -9.0667e-01,  9.5180e-01, -9.5941e-01,  1.3018e-01,\n",
       "          9.9952e-01,  3.0064e-01, -7.7323e-01, -1.4520e-02, -2.0530e-01,\n",
       "          9.0659e-02,  6.5231e-02,  2.7917e-01, -9.1259e-01, -2.6135e-01,\n",
       "         -3.9245e-03,  6.8573e-02,  3.1342e-02,  5.8983e-02,  4.3043e-01,\n",
       "          6.0876e-02, -4.5310e-01, -4.3388e-01,  1.2148e-01,  1.5830e-01,\n",
       "          4.0280e-01, -1.4615e-01,  4.0169e-03, -8.5676e-02,  9.2121e-02,\n",
       "         -6.8131e-01, -8.7510e-02, -1.6906e-01, -9.9675e-01,  4.1637e-01,\n",
       "         -9.9998e-01, -2.1909e-01, -5.8447e-01, -1.9556e-01,  6.6551e-01,\n",
       "          6.3599e-01, -1.6331e-02, -5.3139e-01,  4.0833e-02,  8.7109e-01,\n",
       "          5.3741e-01, -1.1406e-01,  4.6146e-01, -4.0081e-01, -1.1076e-02,\n",
       "          3.8023e-02, -1.2676e-02,  7.5991e-02,  6.3294e-01, -2.6375e-02,\n",
       "          9.9998e-01,  6.9458e-02, -1.2813e-01, -6.0937e-01,  8.4336e-02,\n",
       "         -9.2869e-02,  9.9975e-01, -2.2487e-01, -9.4186e-01,  1.4854e-01,\n",
       "         -4.1167e-01, -6.7908e-01,  2.7211e-01,  4.4046e-02, -3.7530e-01,\n",
       "         -2.4689e-01,  7.1481e-01,  2.2213e-01, -5.4074e-01,  2.4521e-01,\n",
       "         -1.0859e-01, -1.6134e-01, -3.4612e-02,  2.4724e-02,  9.8332e-01,\n",
       "          9.3095e-02,  5.8383e-01,  1.3259e-01, -1.0415e-02,  9.4429e-01,\n",
       "          1.1521e-01, -4.8873e-01, -1.2512e-01,  9.9984e-01,  1.4875e-01,\n",
       "         -8.2864e-01,  4.1079e-01, -8.8411e-01, -1.2098e-01, -8.2743e-01,\n",
       "          1.7618e-01,  7.3778e-02,  7.9333e-01, -5.0684e-02,  8.7399e-01,\n",
       "          5.0246e-01, -1.6108e-01,  1.1248e-01,  3.5764e-01,  1.1404e-01,\n",
       "         -8.2349e-01, -9.8152e-01, -9.7818e-01,  1.2230e-01, -3.2256e-01,\n",
       "          8.0878e-02,  1.5122e-01, -3.3599e-02,  5.9663e-02,  2.4023e-01,\n",
       "         -9.9994e-01,  8.9609e-01,  1.2907e-01,  1.8237e-01,  9.4312e-01,\n",
       "          3.4111e-01,  9.1283e-02,  2.2720e-01, -9.7261e-01, -5.9929e-01,\n",
       "         -1.2034e-01, -1.5286e-01,  2.9834e-01,  3.6463e-01,  8.0139e-01,\n",
       "          9.1167e-02, -4.0741e-01, -2.7015e-01,  3.9396e-01, -8.5776e-01,\n",
       "         -9.9033e-01,  3.4666e-01,  4.5750e-01, -4.5639e-01,  9.4473e-01,\n",
       "         -5.4878e-01, -5.1930e-02,  5.1316e-01, -7.3514e-02,  2.4207e-01,\n",
       "          4.8135e-01,  3.8606e-02, -2.8440e-02,  1.7809e-01,  7.8727e-01,\n",
       "          6.3135e-01,  9.6980e-01, -2.7159e-02,  3.8341e-01,  1.9991e-01,\n",
       "          1.2488e-01,  8.6438e-01, -9.1204e-01,  1.0499e-01,  4.7784e-02,\n",
       "          8.5155e-02,  2.0747e-02, -6.9169e-02, -6.1411e-01,  2.2829e-01,\n",
       "         -1.9920e-01,  2.9203e-01, -1.9068e-01,  2.2280e-01, -2.7858e-01,\n",
       "         -7.6414e-02, -4.8481e-01, -1.8306e-01,  5.7546e-01,  2.0491e-01,\n",
       "          8.1567e-01,  5.1150e-01,  3.3822e-03, -1.3103e-01,  9.0178e-02,\n",
       "          1.1301e-01, -9.0457e-01,  2.9397e-01,  1.4592e-01,  4.3439e-01,\n",
       "          2.7868e-01, -2.3184e-01,  7.5329e-01, -3.0570e-01, -3.6176e-02,\n",
       "         -2.0061e-01, -3.5751e-01,  4.6212e-01, -3.2286e-01, -4.2739e-01,\n",
       "         -2.8510e-01,  2.8154e-01,  1.6693e-01,  9.8901e-01, -2.2021e-02,\n",
       "          1.1078e-01, -9.6961e-02, -1.4179e-01,  3.7853e-01, -1.1074e-01,\n",
       "         -9.9991e-01,  1.7061e-01,  2.6310e-01,  8.6468e-02,  2.8642e-02,\n",
       "          3.3017e-01,  2.1984e-02, -7.9056e-01, -1.3719e-01,  3.3066e-01,\n",
       "          1.9607e-01, -4.0280e-01,  8.9026e-02,  4.6196e-01,  7.5596e-01,\n",
       "          2.7176e-01,  6.7279e-01,  2.9448e-01,  6.1445e-01,  5.7248e-01,\n",
       "         -2.2805e-01, -4.5208e-01,  8.2244e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
